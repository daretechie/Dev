{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f22d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da357595",
   "metadata": {},
   "source": [
    "### LOADING SHAKESPEAREâ€™S TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70152bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file( 'shakespeare.txt',\n",
    "                                   'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b64cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb' ).read().decode(encoding = 'utf-8').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f69eb9",
   "metadata": {},
   "source": [
    "### PREPARING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select all the characters from character number 300,000 up until\n",
    "# 800,000. So we are processing a total of 500,000 characters\n",
    "\n",
    "text = text[ 300000 : 800000 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbed7a",
   "metadata": {},
   "source": [
    "### CONVERTING TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e00c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = dict ((i, c) for i, c in enumerate (characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a6453",
   "metadata": {},
   "source": [
    "### SPLITTING TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19637bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40 #  base sentences will be 40 characters long \n",
    "STEP_SIZE = 3  #  jump three characters from the start of one sentence\n",
    "sentences = [] #  ext sequences will be the input\n",
    "next_char = [] #   results or the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text)-SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i:i+SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffb24f",
   "metadata": {},
   "source": [
    "### CONVERT TO NUMPY FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters), dtype = np.bool))\n",
    "\n",
    "y = np.zeros((len(sentences), len(characters), dtype = np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(422, dtype =np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "        y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105a511",
   "metadata": {},
   "source": [
    "### BUILD RECURRENT NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f58b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(character))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3631a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size = 256, epochs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f4309",
   "metadata": {},
   "source": [
    "### HELPER FUNCTION\n",
    "\n",
    "Function to generate some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Link: https://keras.io/examples/lstm_text_generation/\n",
    "# temp indicates how risky or how unusual the pick shall be\n",
    "\n",
    "def sample(preds, temp=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temp\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24ddf1",
   "metadata": {},
   "source": [
    "### GENERATING TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_text(length, temp):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = \"\"\n",
    "    sentence = text[start_index:start_index + SEQ_LENTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_index[char]] = 1\n",
    "            pred = model.predict(x_pred, verbose = 0)[0]\n",
    "        next_index = sample(pred, temp)\n",
    "        next_character = index_to_char[next_index]\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae35037",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (generate_text( 300 , 0.2 ))\n",
    "print (generate_text( 300 , 0.4 ))\n",
    "print (generate_text( 300 , 0.5 ))\n",
    "print (generate_text( 300 , 0.6 ))\n",
    "print (generate_text( 300 , 0.7 ))\n",
    "print (generate_text( 300 , 0.8 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967975b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
